{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs versus Cats Redux Competition on Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reset python environment\n",
    "%reset -f\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "home_directory = os.getcwd()\n",
    "dataset_directory = home_directory + '/datasets/dogs-vs-cats-redux-kernels-edition/'\n",
    "\n",
    "training_dataset_dir = dataset_directory + '/train/'\n",
    "validation_dataset_dir = dataset_directory + '/valid/'\n",
    "test_dataset_dir = dataset_directory + '/test/'\n",
    "\n",
    "sample_dataset_directory = home_directory + '/datasets/dogs-vs-cats-redux-kernels-edition/sample/'\n",
    "sample_training_dataset_dir = sample_dataset_directory + '/train/'\n",
    "sample_validation_dataset_dir = sample_dataset_directory + '/valid/'\n",
    "sample_test_dataset_dir = sample_dataset_directory + '/test/'\n",
    "\n",
    "# default_device = '/gpu:0'\n",
    "default_device = '/cpu:0'\n",
    "classes = [l.strip() for l in open('synset.txt').readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "                    \n",
    "def filenames_and_labels(path):\n",
    "    cat_filenames = np.array(glob(\"{}/cat/*.jpg\".format(path)))\n",
    "    cat_labels = np.zeros_like(cat_filenames, dtype='float')\n",
    "    dog_filenames = np.array(glob(\"{}/dog/*.jpg\".format(path)))\n",
    "    dog_labels = np.ones_like(dog_filenames, dtype='float')\n",
    "    \n",
    "    return np.concatenate([cat_filenames, dog_filenames]), np.concatenate([cat_labels, dog_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/4, Batch 1/7:\n",
      "\tFetching batch took 0.342 seconds\n",
      "\tExtracting features took 34.143 seconds\n",
      "\tProcessing 32 images 34.487 seconds\n",
      "\n",
      "Epoch 1/4, Batch 2/7:\n",
      "\tFetching batch took 0.071 seconds\n",
      "\tExtracting features took 33.090 seconds\n",
      "\tProcessing 32 images 33.161 seconds\n",
      "\n",
      "Epoch 1/4, Batch 3/7:\n",
      "\tFetching batch took 0.052 seconds\n",
      "\tExtracting features took 27.242 seconds\n",
      "\tProcessing 32 images 27.294 seconds\n",
      "\n",
      "Epoch 1/4, Batch 4/7:\n",
      "\tFetching batch took 0.055 seconds\n",
      "\tExtracting features took 26.428 seconds\n",
      "\tProcessing 32 images 26.483 seconds\n",
      "\n",
      "Epoch 1/4, Batch 5/7:\n",
      "\tFetching batch took 0.059 seconds\n",
      "\tExtracting features took 26.924 seconds\n",
      "\tProcessing 32 images 26.983 seconds\n",
      "\n",
      "Epoch 1/4, Batch 6/7:\n",
      "\tFetching batch took 0.071 seconds\n",
      "\tExtracting features took 32.275 seconds\n",
      "\tProcessing 32 images 32.346 seconds\n",
      "\n",
      "Epoch 1/4, Batch 7/7:\n",
      "\tFetching batch took 0.073 seconds\n",
      "\tExtracting features took 30.528 seconds\n",
      "\tProcessing 32 images 30.601 seconds\n",
      "\n",
      "Epoch 2/4, Batch 1/7:\n",
      "\tFetching batch took 0.071 seconds\n",
      "\tExtracting features took 27.073 seconds\n",
      "\tProcessing 32 images 27.145 seconds\n",
      "\n",
      "Epoch 2/4, Batch 2/7:\n",
      "\tFetching batch took 0.081 seconds\n",
      "\tExtracting features took 32.074 seconds\n",
      "\tProcessing 32 images 32.156 seconds\n",
      "\n",
      "Epoch 2/4, Batch 3/7:\n",
      "\tFetching batch took 0.073 seconds\n",
      "\tExtracting features took 30.135 seconds\n",
      "\tProcessing 32 images 30.208 seconds\n",
      "\n",
      "Epoch 2/4, Batch 4/7:\n",
      "\tFetching batch took 0.066 seconds\n",
      "\tExtracting features took 32.637 seconds\n",
      "\tProcessing 32 images 32.704 seconds\n",
      "\n",
      "Epoch 2/4, Batch 5/7:\n",
      "\tFetching batch took 0.083 seconds\n",
      "\tExtracting features took 30.524 seconds\n",
      "\tProcessing 32 images 30.608 seconds\n",
      "\n",
      "Epoch 2/4, Batch 6/7:\n",
      "\tFetching batch took 0.051 seconds\n",
      "\tExtracting features took 28.078 seconds\n",
      "\tProcessing 32 images 28.130 seconds\n",
      "\n",
      "Epoch 3/4, Batch 1/7:\n",
      "\tFetching batch took 0.054 seconds\n",
      "\tExtracting features took 27.352 seconds\n",
      "\tProcessing 32 images 27.406 seconds\n",
      "\n",
      "Epoch 3/4, Batch 2/7:\n",
      "\tFetching batch took 0.066 seconds\n",
      "\tExtracting features took 26.850 seconds\n",
      "\tProcessing 32 images 26.916 seconds\n",
      "\n",
      "Epoch 3/4, Batch 3/7:\n",
      "\tFetching batch took 0.056 seconds\n",
      "\tExtracting features took 26.300 seconds\n",
      "\tProcessing 32 images 26.356 seconds\n",
      "\n",
      "Epoch 3/4, Batch 4/7:\n",
      "\tFetching batch took 0.071 seconds\n",
      "\tExtracting features took 28.243 seconds\n",
      "\tProcessing 32 images 28.315 seconds\n",
      "\n",
      "Epoch 3/4, Batch 5/7:\n",
      "\tFetching batch took 0.062 seconds\n",
      "\tExtracting features took 30.799 seconds\n",
      "\tProcessing 32 images 30.862 seconds\n",
      "\n",
      "Epoch 3/4, Batch 6/7:\n",
      "\tFetching batch took 0.113 seconds\n",
      "\tExtracting features took 30.802 seconds\n",
      "\tProcessing 32 images 30.916 seconds\n",
      "\n",
      "Epoch 4/4, Batch 1/7:\n",
      "\tFetching batch took 0.048 seconds\n",
      "\tExtracting features took 28.203 seconds\n",
      "\tProcessing 32 images 28.251 seconds\n",
      "\n",
      "Epoch 4/4, Batch 2/7:\n",
      "\tFetching batch took 0.055 seconds\n",
      "\tExtracting features took 26.025 seconds\n",
      "\tProcessing 32 images 26.080 seconds\n",
      "\n",
      "Epoch 4/4, Batch 3/7:\n",
      "\tFetching batch took 0.061 seconds\n",
      "\tExtracting features took 26.067 seconds\n",
      "\tProcessing 32 images 26.128 seconds\n",
      "\n",
      "Epoch 4/4, Batch 4/7:\n",
      "\tFetching batch took 0.057 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_image_utils as tiu\n",
    "from vgg16 import Vgg16Model\n",
    "\n",
    "batch_size = 32\n",
    "augmentation_epochs = 4\n",
    "    \n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    filenames, labels = filenames_and_labels(sample_training_dataset_dir)\n",
    "    \n",
    "    filename_queue, label_queue = tf.train.slice_input_producer(\n",
    "                        [\n",
    "                            tf.convert_to_tensor(filenames, dtype=tf.string),\n",
    "                            tf.convert_to_tensor(labels, dtype=tf.float32)\n",
    "                        ], num_epochs=augmentation_epochs, shuffle=False)\n",
    "    \n",
    "    image = tiu.load_image(filename_queue, size=(224, 224))\n",
    "    image = tiu.distort_image(image)\n",
    "    image = tiu.vgg16_preprocess(image, shape=(224, 224, 3))\n",
    "    \n",
    "    batched_data = tf.train.batch(\n",
    "        [image, label_queue, filename_queue],\n",
    "        batch_size=batch_size,\n",
    "        num_threads=4,\n",
    "        enqueue_many=False,\n",
    "        capacity=3 * batch_size)\n",
    "    \n",
    "    inputs = tf.placeholder(tf.float32, shape=(None, 224, 224, 3), name=\"input\")\n",
    "    model = Vgg16Model()\n",
    "    model.build(inputs)\n",
    "\n",
    "    sess.run([\n",
    "        tf.local_variables_initializer(),\n",
    "        tf.global_variables_initializer()\n",
    "    ])\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "    \n",
    "    codes = []\n",
    "    \n",
    "    num_unique_files = len(filenames)\n",
    "    num_files_to_process = num_unique_files * augmentation_epochs\n",
    "    num_batches = num_unique_files // batch_size\n",
    "    \n",
    "    if num_unique_files % batch_size != 0:\n",
    "        num_batches = num_batches + 1\n",
    "    \n",
    "    num_processed_files = 0\n",
    "    \n",
    "    current_epoch = 0\n",
    "    current_batch = 0\n",
    "    \n",
    "    try:\n",
    "        while not coord.should_stop():\n",
    "            current_epoch = num_processed_files // num_unique_files\n",
    "            current_batch = (num_processed_files - (current_epoch * num_unique_files)) // batch_size\n",
    "            \n",
    "            print(\"\\nEpoch {}/{}, Batch {}/{}:\".format(\n",
    "                current_epoch + 1, augmentation_epochs, current_batch + 1, num_batches\n",
    "            ))\n",
    "            \n",
    "            t0 = time.perf_counter()\n",
    "            batch_images, batch_labels, batch_filenames = sess.run(batched_data)\n",
    "            t1 = time.perf_counter()\n",
    "            print(\"\\tFetching batch took {:.3f} seconds\".format(t1-t0))\n",
    "            \n",
    "            # flatten shape of maxpool5: (7, 7, 512) -> 7 * 7 * 512\n",
    "            flattened = tf.reshape(model.max_pool5, shape=(-1, 7 * 7 * 512))\n",
    "            \n",
    "            features = sess.run(flattened, feed_dict={inputs: batch_images})\n",
    "            t2 = time.perf_counter()\n",
    "            print(\"\\tExtracting features took {:.3f} seconds\".format(t2-t1))\n",
    "            \n",
    "            for i, batch_filename in enumerate(batch_filenames):\n",
    "                codes.append([batch_labels[i], batch_filename, features[i]])\n",
    "            \n",
    "            t3 = time.perf_counter()            \n",
    "            num_processed_files = num_processed_files + len(batch_filenames)\n",
    "            print(\"\\tProcessing {} images {:.3f} seconds\".format(len(batch_filenames), t3-t0))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "            print('Done training -- epoch limit reached')\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "\n",
    "np.save('sample_training_codes.npy', np.array(codes, dtype='object'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = np.load('sample_training_codes.npy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
