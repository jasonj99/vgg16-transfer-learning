{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning to detect cats / dogs using Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_mean = [103.939, 116.779, 123.68]\n",
    "classes = [l.strip() for l in open('synset.txt').readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vgg16 Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Vgg16Model:\n",
    "    def __init__(self, weights_path='./vgg16.npy'):\n",
    "        self.weights = np.load('vgg16.npy', encoding='latin1').item()\n",
    "        self.activation_fn = tf.nn.relu\n",
    "        self.conv_padding = 'SAME'\n",
    "        self.pool_padding = 'SAME'\n",
    "        self.use_bias = True\n",
    "\n",
    "    def build(self, input_tensor, trainable=False):\n",
    "        self.conv1_1 = self.conv2d(input_tensor, 'conv1_1', 64, trainable)\n",
    "        self.conv1_2 = self.conv2d(self.conv1_1, 'conv1_2', 64, trainable)\n",
    "\n",
    "        # Max-pooling is performed over a 2 Ã— 2 pixel window, with stride 2.\n",
    "        self.max_pool1 = tf.layers.max_pooling2d(self.conv1_2, (2, 2), (2, 2), padding=self.pool_padding)\n",
    "\n",
    "        self.conv2_1 = self.conv2d(self.max_pool1, 'conv2_1', 128, trainable)\n",
    "        self.conv2_2 = self.conv2d(self.conv2_1, 'conv2_2', 128, trainable)\n",
    "\n",
    "        self.max_pool2 = tf.layers.max_pooling2d(self.conv2_2, (2, 2), (2, 2), padding=self.pool_padding)\n",
    "\n",
    "        self.conv3_1 = self.conv2d(self.max_pool2, 'conv3_1', 256, trainable)\n",
    "        self.conv3_2 = self.conv2d(self.conv3_1, 'conv3_2', 256, trainable)\n",
    "        self.conv3_3 = self.conv2d(self.conv3_2, 'conv3_3', 256, trainable)\n",
    "\n",
    "        self.max_pool3 = tf.layers.max_pooling2d(self.conv3_3, (2, 2), (2, 2), padding=self.pool_padding)\n",
    "\n",
    "        self.conv4_1 = self.conv2d(self.max_pool3, 'conv4_1', 512, trainable)\n",
    "        self.conv4_2 = self.conv2d(self.conv4_1, 'conv4_2', 512, trainable)\n",
    "        self.conv4_3 = self.conv2d(self.conv4_2, 'conv4_3', 512, trainable)\n",
    "\n",
    "        self.max_pool4 = tf.layers.max_pooling2d(self.conv4_3, (2, 2), (2, 2), padding=self.pool_padding)\n",
    "\n",
    "        self.conv5_1 = self.conv2d(self.max_pool4, 'conv5_1', 512, trainable)\n",
    "        self.conv5_2 = self.conv2d(self.conv5_1, 'conv5_2', 512, trainable)\n",
    "        self.conv5_3 = self.conv2d(self.conv5_2, 'conv5_3', 512, trainable)\n",
    "\n",
    "        self.max_pool5 = tf.layers.max_pooling2d(self.conv5_3, (2, 2), (2, 2), padding=self.pool_padding)\n",
    "\n",
    "        reshaped = tf.reshape(self.max_pool5, shape=(-1, 7 * 7 * 512))\n",
    "\n",
    "        self.fc6 = self.fc(reshaped, 'fc6', 4096, trainable)\n",
    "        self.fc7 = self.fc(self.fc6, 'fc7', 4096, trainable)\n",
    "\n",
    "        self.fc8 = self.fc(self.fc7, 'fc8', 1000, trainable)\n",
    "\n",
    "        self.predictions = tf.nn.softmax(self.fc8, name='predictions')\n",
    "\n",
    "    def conv2d(self, layer, name, n_filters, trainable, k_size=3):\n",
    "        return tf.layers.conv2d(layer, n_filters, kernel_size=(k_size, k_size),\n",
    "                                activation=self.activation_fn, padding=self.conv_padding, name=name, trainable=trainable,\n",
    "                                kernel_initializer=tf.constant_initializer(self.weights[name][0], dtype=tf.float32),\n",
    "                                bias_initializer=tf.constant_initializer(self.weights[name][1], dtype=tf.float32),\n",
    "                                use_bias=self.use_bias)\n",
    "\n",
    "    def fc(self, layer, name, size, trainable):\n",
    "        return tf.layers.dense(layer, size, activation=self.activation_fn,\n",
    "                               name=name, trainable=trainable,\n",
    "                               kernel_initializer=tf.constant_initializer(self.weights[name][0], dtype=tf.float32),\n",
    "                               bias_initializer=tf.constant_initializer(self.weights[name][1], dtype=tf.float32),\n",
    "                               use_bias=self.use_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images conversion for Vgg16\n",
    "\n",
    "Images have to be of dimension (224, 224, 3). The last dimension is ordered BGR (blue, green, red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://github.com/machrisaa/tensorflow-vgg/blob/master/utils.py\n",
    "def load_image(image_path, mean=vgg_mean):\n",
    "    image = skimage.io.imread(image_path)\n",
    "\n",
    "    image = image.astype(float)\n",
    "    \n",
    "    short_edge = min(image.shape[:2])\n",
    "    yy = int((image.shape[0] - short_edge) / 2)\n",
    "    xx = int((image.shape[1] - short_edge) / 2)\n",
    "    crop_image = image[yy: yy + short_edge, xx: xx + short_edge]\n",
    "    \n",
    "    resized_image = skimage.transform.resize(crop_image, (224, 224), mode='constant') \n",
    "            \n",
    "    bgr = resized_image[:,:,::-1] - mean\n",
    "    \n",
    "    return bgr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Vgg16 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "dataset_dir = './datasets/dogs-vs-cats-redux-kernels-edition/train/'\n",
    "filenames = os.listdir(dataset_dir)\n",
    "num_files = len(filenames)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "num_batches = int(math.ceil(num_files / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# create mapping of filename -> vgg features\n",
    "codes_fc6 = {}\n",
    "codes_fc7 = {}\n",
    "predictions = {}\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:    \n",
    "        _input = tf.placeholder(tf.float32, shape=(None, 224, 224, 3), name=\"images\")\n",
    "\n",
    "        vgg = Vgg16Model()\n",
    "        vgg.build(_input)\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        for i in range(num_batches):\n",
    "            batch_filenames = filenames[i*batch_size : ((i+1)*batch_size)]\n",
    "\n",
    "            print(\"batch {} of {}\".format(i+1, num_batches))\n",
    "\n",
    "            start = time.time()\n",
    "            images = np.array([load_image(dataset_dir + f) for f in batch_filenames])\n",
    "            end = time.time()\n",
    "            print(\"\\timage loading took {:.4f} sec\".format(end-start))\n",
    "\n",
    "            start = end\n",
    "            \n",
    "            batch_codes_fc6, batch_codes_fc7 = sess.run(\n",
    "                [vgg.fc6, vgg.fc7],\n",
    "                feed_dict={ _input: images }\n",
    "            )\n",
    "            \n",
    "            end = time.time()\n",
    "            print(\"\\tprediction took {:.4f} sec\".format(end-start))\n",
    "\n",
    "            for i, filename in enumerate(batch_filenames):\n",
    "                codes_fc6[filename] = batch_codes_fc6[i]\n",
    "                codes_fc7[filename] = batch_codes_fc7[i]\n",
    "\n",
    "        np.save('codes_fc6.npy', codes_fc6)\n",
    "        np.save('codes_fc7.npy', codes_fc7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint - Vgg16 Features extracted and serialized\n",
    "\n",
    "The features for each images should be stored in a file called `codes_{layer_name}.npy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reset python environment\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "codes = np.load('codes_fc6.npy')\n",
    "codes = OrderedDict(codes.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys = list(codes.keys())\n",
    "\n",
    "# one hot encode labels\n",
    "labels = np.array([ (1, 0) if name[:3] == 'dog' else (0,1) for name in keys])\n",
    "\n",
    "# extract images\n",
    "images = np.array(list(codes.values()))\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "for i,key in enumerate(keys):\n",
    "    assert (codes.get(key) == images[i]).all()\n",
    "\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.1)\n",
    "\n",
    "\n",
    "train_indices, val_indices = next(splitter.split(images, labels))\n",
    "\n",
    "train_images, train_labels = images[train_indices], labels[train_indices]\n",
    "val_images, val_labels = images[val_indices], labels[val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_batches(x, y, batch_size=32):\n",
    "    num_rows = train_labels.shape[0]\n",
    "    \n",
    "    num_batches = num_rows // batch_size\n",
    "    \n",
    "    if num_rows % batch_size != 0:\n",
    "        num_batches = num_batches + 1\n",
    "\n",
    "    for batch in range(num_batches):\n",
    "        yield x[batch_size * batch: batch_size * (batch + 1)], y[batch_size * batch: batch_size * (batch + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "learning_rate = 0.01\n",
    "keep_prob = 0.5\n",
    "batch_size = 64\n",
    "accuracy_print_steps = 10\n",
    "iteration = 0\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "_images = tf.placeholder(tf.float32, shape=(None, 4096), name='images')\n",
    "_labels = tf.placeholder(tf.float32, shape=(None, 2), name='labels')\n",
    "_keep_prob = tf.placeholder(tf.float32, name='keep_probability')\n",
    "\n",
    "hidden = tf.contrib.layers.fully_connected(_images, 256)\n",
    "hidden = tf.nn.dropout(hidden, keep_prob=_keep_prob, name='hidden_dropout')\n",
    "\n",
    "logits = tf.contrib.layers.fully_connected(hidden, 2, activation_fn=None)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=_labels, name='cross_entropy')\n",
    "\n",
    "cost = tf.reduce_mean(cross_entropy, name='cost')\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "predictions = tf.nn.softmax(logits, name='predictions')\n",
    "\n",
    "correct_predictions = tf.equal(tf.argmax(predictions, 1), tf.argmax(_labels, 1), name='correct_predictions')\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32), name='accuracy')\n",
    "\n",
    "# with tf.device('/gpu:0'):\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_train_images, batch_train_labels in get_batches(train_images, train_labels, batch_size=batch_size):\n",
    "            train_loss, _, p = sess.run(\n",
    "                [cost, optimizer, logits], \n",
    "                feed_dict = { \n",
    "                    _images: batch_train_images,\n",
    "                    _labels: batch_train_labels,\n",
    "                    _keep_prob: keep_prob\n",
    "                })\n",
    "\n",
    "            iteration = iteration + 1\n",
    "\n",
    "            if iteration % accuracy_print_steps == 0:\n",
    "                val_acc = sess.run(accuracy, feed_dict ={\n",
    "                    _images: val_images,\n",
    "                    _labels: val_labels,\n",
    "                    _keep_prob: 1.\n",
    "                })\n",
    "\n",
    "                print('{} / {} Accuracy: {} Loss: {}'.format(epoch + 1, num_epochs, val_acc, train_loss))\n",
    "\n",
    "    ### Save graph and trained variables\n",
    "    import time\n",
    "    from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "\n",
    "    builder = saved_model_builder.SavedModelBuilder('models/model-{}'.format(int(time.time())))\n",
    "\n",
    "    builder.add_meta_graph_and_variables(\n",
    "        sess, [tf.python.saved_model.tag_constants.SERVING],\n",
    "        signature_def_map = {\n",
    "            tf.python.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:\n",
    "            tf.python.saved_model.signature_def_utils.predict_signature_def(\n",
    "                inputs = { tf.python.saved_model.signature_constants.PREDICT_INPUTS: _images },\n",
    "                outputs = { tf.python.saved_model.signature_constants.PREDICT_OUTPUTS: predictions }\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    builder.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load and prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "dataset_dir = './datasets/dogs-vs-cats-redux-kernels-edition/test/'\n",
    "filenames = os.listdir(dataset_dir)\n",
    "num_files = len(filenames)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "num_batches = int(math.ceil(num_files / batch_size))\n",
    "\n",
    "def get_batches(x, y, batch_size=32):\n",
    "    num_rows = train_labels.shape[0]\n",
    "    \n",
    "    num_batches = num_rows // batch_size\n",
    "    \n",
    "    if num_rows % batch_size != 0:\n",
    "        num_batches = num_batches + 1\n",
    "\n",
    "    for batch in range(num_batches):\n",
    "        yield x[batch_size * batch: batch_size * (batch + 1)], y[batch_size * batch: batch_size * (batch + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Vgg16 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# create mapping of filename -> vgg features\n",
    "codes_fc6 = {}\n",
    "codes_fc7 = {}\n",
    "predictions = {}\n",
    "\n",
    "# with tf.device('/gpu:0'):\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:    \n",
    "    _input = tf.placeholder(tf.float32, shape=(None, 224, 224, 3), name=\"images\")\n",
    "\n",
    "    vgg = Vgg16Model()\n",
    "    vgg.build(_input)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        batch_filenames = filenames[i*batch_size : ((i+1)*batch_size)]\n",
    "\n",
    "        print(\"batch {} of {}\".format(i+1, num_batches))\n",
    "\n",
    "        start = time.time()\n",
    "        images = np.array([load_image(dataset_dir + f) for f in batch_filenames])\n",
    "        end = time.time()\n",
    "        print(\"\\timage loading took {:.4f} sec\".format(end-start))\n",
    "\n",
    "        start = end\n",
    "\n",
    "        batch_codes_fc6, batch_codes_fc7 = sess.run(\n",
    "            [vgg.fc6, vgg.fc7],\n",
    "            feed_dict={ _binput: images }\n",
    "        )\n",
    "\n",
    "        end = time.time()\n",
    "        print(\"\\tprediction took {:.4f} sec\".format(end-start))\n",
    "\n",
    "        for i, filename in enumerate(batch_filenames):\n",
    "            codes_fc6[filename] = batch_codes_fc6[i]\n",
    "            codes_fc7[filename] = batch_codes_fc7[i]\n",
    "\n",
    "    np.save('test_codes_fc6.npy', codes_fc6)\n",
    "    np.save('test_codes_fc7.npy', codes_fc7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "codes = np.load('test_codes_fc6.npy')\n",
    "codes = OrderedDict(codes.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys = list(codes.keys())\n",
    "keys[2:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.saved_model import loader\n",
    "\n",
    "# keys = codes_fc6\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    loader.load(sess, [tf.python.saved_model.tag_constants.SERVING], 'models/model-1494245693/')\n",
    "\n",
    "    \n",
    "    s_keep_probability = sess.graph.get_tensor_by_name('keep_probability:0')\n",
    "    s_images = sess.graph.get_tensor_by_name('images:0')\n",
    "    s_predictions = sess.graph.get_tensor_by_name('predictions:0')\n",
    "    \n",
    "    pred = sess.run(s_predictions, feed_dict={\n",
    "        s_images: list(codes.values())[2:60],\n",
    "        s_keep_probability: 1\n",
    "    })\n",
    "    \n",
    "    print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
